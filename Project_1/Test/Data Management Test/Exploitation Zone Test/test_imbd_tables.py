import unittest
from unittest.mock import patch, MagicMock
from delta import configure_spark_with_delta_pip
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg
from pyspark.sql import DataFrame
from pathlib import Path
import shutil   
import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../Python/Data_Management/Exploitation_Zone')))
from imbd_tables import ( # type: ignore
    imbd_principals_names_ratings_tables_join,
    imbd_compute_people_movies_kpis,
    imbd_titles_episodes_ratings_tables_join,
    imbd_compute_episodes_ratings_kpis,
    imbd_tables
)
from datetime import datetime

class TestImbdTables(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        builder = (
        SparkSession.builder
        .master("local[1]")
        .appName("TestImbdTables")
        .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension")
        .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")
        )
        cls.spark = configure_spark_with_delta_pip(builder).getOrCreate()

    @classmethod
    def tearDownClass(cls):
        cls.spark.stop()

    def test_imbd_principals_names_ratings_tables_join(self):
        principals = self.spark.createDataFrame([
            ("nm001", "tt001", "actor"),
        ], ["nconst", "tconst", "category"])

        names = self.spark.createDataFrame([
            ("nm001", "John Doe"),
        ], ["nconst", "primaryName"])

        ratings = self.spark.createDataFrame([
            ("tt001", 8.5),
        ], ["tconst", "averageRating"])

        result = imbd_principals_names_ratings_tables_join(principals, names, ratings)
        self.assertEqual(result.count(), 1)
        self.assertEqual(result.columns, ["id_person", "person_name", "category", "average_rating", "id_title"])
        self.assertAlmostEqual(result.select("average_rating").first()[0], 8.5)

    def test_imbd_compute_people_movies_kpis(self):
        people_movies = self.spark.createDataFrame([
            ("nm001", "John Doe", "actor", 8.5, "tt001"),
            ("nm001", "John Doe", "actor", 7.5, "tt002"),
        ], ["id_person", "person_name", "category", "average_rating", "id_title"])

        result = imbd_compute_people_movies_kpis(people_movies)
        row = result.first()
        self.assertEqual(row["num_titles"], 2)
        self.assertAlmostEqual(row["avg_rating"], 8.0)

    def test_imbd_titles_episodes_ratings_tables_join(self):
        titles = self.spark.createDataFrame([
            ("tt001", "Title 1", False, 2020, ["Drama", "Action"]),
        ], ["tconst", "originalTitle", "isAdult", "startYear", "genres"])

        episodes = self.spark.createDataFrame([
            ("tt001", 1, 2),
        ], ["tconst", "seasonNumber", "episodeNumber"])

        ratings = self.spark.createDataFrame([
            ("tt001", 8.5, 1000),
        ], ["tconst", "averageRating", "numVotes"])

        result = imbd_titles_episodes_ratings_tables_join(titles, episodes, ratings)
        self.assertEqual(result.count(), 1)
        self.assertEqual(result.columns, ["id", "originalTitle", "isAdult", "startYear", "genres", "seasonNumber", "episodeNumber", "averageRating", "numVotes"])
        self.assertAlmostEqual(result.select("numVotes").first()[0], 1000)
        self.assertAlmostEqual(result.select("averageRating").first()[0], 8.5)
    
    def test_imbd_compute_episodes_ratings_kpis(self):
        episodes_ratings = self.spark.createDataFrame([
            ("tt001", 1, 2, 8.5, 1000),
            ("tt002", 1, 3, 7.5, 500),
            ("tt003", 2, 8, 8.8, 1500),
        ], ["id", "seasonNumber", "episodeNumber", "averageRating", "numVotes"])

        avg_all_movies = episodes_ratings.agg(avg("averageRating").alias("avg_rating")).collect()[0]["avg_rating"]

        result = imbd_compute_episodes_ratings_kpis(episodes_ratings, avg_all_movies)
        self.assertEqual(result.count(), 3)
        self.assertEqual(result.select("trend").first()[0], True)
        self.assertAlmostEqual(result.select("score").first()[0], 8.5 * 1000)
        self.assertEqual(result.select("total_episodes").collect()[1][0], 3)

    @patch("imbd_tables.load_delta_tables")
    @patch("imbd_tables.imbd_principals_names_ratings_tables_join")
    @patch("imbd_tables.imbd_compute_people_movies_kpis")
    @patch("imbd_tables.imbd_titles_episodes_ratings_tables_join")
    @patch("imbd_tables.imbd_compute_episodes_ratings_kpis")
    def test_imbd_tables(self,
                         mock_compute_episodes_kpis,
                         mock_titles_episodes_ratings_join,
                         mock_compute_people_kpis,
                         mock_principals_names_ratings_join,
                         mock_load_delta_tables):
        # Mock DataFrames to be returned by mocks
        mock_principals_df = MagicMock(spec=DataFrame)
        mock_names_df = MagicMock(spec=DataFrame)
        mock_ratings_df = MagicMock(spec=DataFrame)
        mock_episodes_df = MagicMock(spec=DataFrame)
        mock_titles_df = MagicMock(spec=DataFrame)

        # Mock dict returned by load_delta_tables
        mock_load_delta_tables.return_value = {
            'imbd_title_principals': mock_principals_df,
            'imbd_name_basics': mock_names_df,
            'imbd_title_ratings': mock_ratings_df,
            'imbd_title_episode': mock_episodes_df,
            'imbd_title_basics': mock_titles_df
        }

        # Mock outputs of each step function
        mock_people_movies_df = MagicMock(spec=DataFrame)
        mock_people_movies_kpi_df = MagicMock(spec=DataFrame)
        mock_episode_ratings_df = MagicMock(spec=DataFrame)
        mock_episode_ratings_kpi_df = MagicMock(spec=DataFrame)

        mock_principals_names_ratings_join.return_value = mock_people_movies_df
        mock_compute_people_kpis.return_value = mock_people_movies_kpi_df
        mock_titles_episodes_ratings_join.return_value = mock_episode_ratings_df
        mock_compute_episodes_kpis.return_value = mock_episode_ratings_kpi_df

        # Mock the averageRating aggregation and collect
        # ratings_df.select(...).agg(...).collect()[0][0]
        # We have to simulate this chain of calls on mock_ratings_df
        mock_avg_row = MagicMock()
        mock_avg_row.__getitem__.return_value = 7.5  # average rating value
        mock_ratings_df.select.return_value.agg.return_value.collect.return_value = [mock_avg_row]

        # Provide a temporary exploitation path
        temp_exploitation_path = Path("test_exploitation_zone")
        temp_exploitation_path.mkdir(exist_ok=True)

        # Run the function
        imbd_tables(self.spark,
                    imbd_delta_path="does_not_matter_for_mocking",
                    exploitation_zone_base=str(temp_exploitation_path))

        # Check if the mocks were called as expected
        mock_load_delta_tables.assert_called_once()
        mock_principals_names_ratings_join.assert_called_once_with(mock_principals_df, mock_names_df, mock_ratings_df)
        mock_compute_people_kpis.assert_called_once_with(mock_people_movies_df)
        mock_titles_episodes_ratings_join.assert_called_once_with(mock_titles_df, mock_episodes_df, mock_ratings_df)
        mock_compute_episodes_kpis.assert_called_once_with(mock_episode_ratings_df, 7.5)

        # Check if write calls were made on the final DataFrames with 'delta' format and 'overwrite' mode
        mock_people_movies_kpi_df.write.format.assert_called_with("delta")
        mock_people_movies_kpi_df.write.format.return_value.mode.assert_called_with("overwrite")
        mock_episode_ratings_kpi_df.write.format.assert_called_with("delta")
        mock_episode_ratings_kpi_df.write.format.return_value.mode.assert_called_with("overwrite")

        # Cleanup
        shutil.rmtree(temp_exploitation_path, ignore_errors=True)


if __name__ == "__main__":
    unittest.main()