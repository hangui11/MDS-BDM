import os
from pathlib import Path
from pyspark.sql import functions as F
from delta import *

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils import *

def ml_tag_join_table(genome_score_df, genome_tag_df):
    join_df = genome_score_df.join(genome_tag_df, on="tagId").select("movieId", "tag")
    result_df = join_df.groupBy("movieId").agg(
        F.collect_list("tag").alias("tags")
    )
    return result_df

def ml_movie_and_ml_tag_join_table(ml_movie_df, ml_tag_df):
    join_df = ml_movie_df.join(ml_tag_df, on='movieId')
    return join_df

def ml_movie_tables(spark, ml_movie_delta_path='../../../Data Management/Trusted Zone/ml-20m/',
                    exploitation_zone_base='../../../Data Management/Exploitation Zone/'):
    
    # spark = get_spark_session()
    exploitation_zone_base = Path(exploitation_zone_base)
    exploitation_zone_base.mkdir(parents=True, exist_ok=True)

    ml_20m_tables = load_delta_tables(ml_movie_delta_path, spark)

    ml_tag_df = ml_tag_join_table(ml_20m_tables['ml-20m_genome_scores'], ml_20m_tables['ml-20m_genome_tags'])
    ml_movie_join_df = ml_movie_and_ml_tag_join_table(ml_20m_tables['ml-20m_movie'], ml_tag_df)

    ml_20m_exploitation_path = Path(exploitation_zone_base) / 'ml-20m'
    ml_20m_exploitation_path.mkdir(parents=True, exist_ok=True)
    ml_movie_join_df.write.format('delta').mode('overwrite').save(str(ml_20m_exploitation_path / 'ml-20m_movie'))
    ml_20m_tables['ml-20m_rating'].write.format('delta').mode('overwrite').save(str(ml_20m_exploitation_path / 'ml-20m_rating'))
    ml_20m_tables['ml-20m_tag'].write.format('delta').mode('overwrite').save(str(ml_20m_exploitation_path / 'ml-20m_tag'))

    # spark.stop()

# ml_movie_tables()
